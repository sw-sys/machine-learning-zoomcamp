{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7583f410-bacb-4c50-ab15-9d7161f8a005",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\r\n",
    "1. Evaluation metrics: session overview\r\n",
    "2. Accuracy and dummy model\r\n",
    "3. Confusion Table\r\n",
    "4. Precision and Recall\r\n",
    "5. ROC Curves\r\n",
    "6. ROC AUC\r\n",
    "7. Cross Validation\r\n",
    "8.\n",
    "\n",
    "\n",
    "\n",
    "Homework link: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw04 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009dfe00-518c-44dc-9782-190645c72a9d",
   "metadata": {},
   "source": [
    "#### In this homework, we will use the lead scoring dataset Bank Marketing dataset. Download it \r\n",
    "\r\n",
    "In this dataset our desired target for classification task will be converted variable - has the client signed up to the platform or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0115f4a-5981-4734-b3bb-cd845a8a206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f58aab0-c647-444d-8f15-0303ba6cf506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lead_source</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>social_media</td>\n",
       "      <td>events</td>\n",
       "      <td>paid_ads</td>\n",
       "      <td>referral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>NaN</td>\n",
       "      <td>retail</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>retail</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>79450.0</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>85012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <td>unemployed</td>\n",
       "      <td>employed</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self_employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>south_america</td>\n",
       "      <td>south_america</td>\n",
       "      <td>australia</td>\n",
       "      <td>australia</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converted</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0              1           2          3  \\\n",
       "lead_source                    paid_ads   social_media      events   paid_ads   \n",
       "industry                            NaN         retail  healthcare     retail   \n",
       "number_of_courses_viewed              1              1           5          2   \n",
       "annual_income                   79450.0        46992.0     78796.0    83843.0   \n",
       "employment_status            unemployed       employed  unemployed        NaN   \n",
       "location                  south_america  south_america   australia  australia   \n",
       "interaction_count                     4              1           3          1   \n",
       "lead_score                         0.94            0.8        0.69       0.87   \n",
       "converted                             1              0           1          0   \n",
       "\n",
       "                                      4  \n",
       "lead_source                    referral  \n",
       "industry                      education  \n",
       "number_of_courses_viewed              3  \n",
       "annual_income                   85012.0  \n",
       "employment_status         self_employed  \n",
       "location                         europe  \n",
       "interaction_count                     3  \n",
       "lead_score                         0.62  \n",
       "converted                             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "#df.head()\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45a0ffa-ed4b-402b-b972-0b45a58efe47",
   "metadata": {},
   "source": [
    "# Data Prep\r",
    "ate=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b0b687-d5a1-4224-8634-a47af4033cca",
   "metadata": {},
   "source": [
    "#### Check if the missing values are presented in the features.\n",
    "### If there are missing values:\n",
    "##### 1. For caterogiral features, replace them with 'NA'\n",
    "##### 2. For numerical features, replace with with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe59cbd-78a0-461b-b70b-319c1e89a404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a0e84c9-2b4f-4f2d-a7ec-e9ea68cf1456",
   "metadata": {},
   "source": [
    "#### Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split function for that with random_state=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f4d90c-37f5-4f63-996f-38cafa669328",
   "metadata": {},
   "source": [
    "# Question 1: ROC AUC feature importance\n",
    "\n",
    "feature importance:\n",
    "- mutual info https://www.youtube.com/watch?v=_u2YaGT6RN0&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=34\n",
    "- correlation https://www.youtube.com/watch?v=mz1707QVxiY&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=35\n",
    "\r",
    "### \n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\r\n",
    "\r\n",
    "Let's do that\r\n",
    "\r\n",
    "For each numerical variable, use it as score (aka prediction) and compute the AUC with the y variable as ground truth.\r\n",
    "Use the training dataset for that\r\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\r\n",
    "\r\n",
    "(e.g. -df_train['balance'])\r\n",
    "\r\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target variable. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\r\n",
    "\r\n",
    "Which numerical variable (among the following 4) has the highest AUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268b2f9-e30e-4dc4-98b2-9cb768158227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab5c4521-e81a-4289-b87b-2ab031643157",
   "metadata": {},
   "source": [
    "# Question 2: Training the model\n",
    "one-hot encoding video https://www.youtube.com/watch?v=L-mjQFN5aR0&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=36\n",
    "\r",
    "#### \n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\r\n",
    "\r\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\r\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1865fcb-1177-4b4f-8919-e027813b9b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c67844-cf33-499e-8508-80730468f03b",
   "metadata": {},
   "source": [
    "# Question 3: Precision and Recall\r\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "For each threshold, compute precision and recall. Plot them. \n",
    "\n",
    "### At which threshold precision and recall curves intersect?\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb24de-b75c-41fe-850c-dbbdab1c3966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "900a0d4f-1f55-4268-9981-af226a3a6f67",
   "metadata": {},
   "source": [
    "# Question 4 : F1 score\r\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\r\n",
    "\r\n",
    "This is the formula for computing F1:1 = 2 (point) then P (point) R over P + R (see https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2025/04-evaluation/homework.md)\r\n",
    "â‹…\r\n",
    "R\r\n",
    "P\r\n",
    "+\r\n",
    "R\r\n",
    "\r\n",
    "Where \r\n",
    "P\r\n",
    " is precision and \r\n",
    "R\r\n",
    " is recall.\r\n",
    "\r\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\r\n",
    "\r\n",
    "At which hold F1 is maximal?\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204b5d7-c805-428d-953a-7e793c408575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eda1ef7f-33f8-476f-8d53-2f809aa38f7f",
   "metadata": {},
   "source": [
    "# Question 5: 5-Fold CV\r\n",
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\r\n",
    "\r\n",
    "KFold(n_splits=5, shuffle=True, random_state\n",
    "=1)\r\n",
    "Iterate over different folds of df_full_train\r\n",
    "Split the data into train and validation\r\n",
    "Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\r\n",
    "Use AUC to evaluate the model on vali\n",
    "dation\r\n",
    "How large is standard deviation of the scores across differen0001\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c4b3f-25f7-4ef0-bb8e-eab35d02a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "01\n",
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66405bd2-7e21-4ceb-9109-1e2a21b47242",
   "metadata": {},
   "source": [
    "# Question 6: Hyperparameter Tuning\r\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\r\n",
    "\r\n",
    "Iterate over the following C values: [0.000001, 0.001,\n",
    " 1]\r\n",
    "Initialize KFold with the same parameters as previously\r\n",
    "Use these parameters for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\r\n",
    "Compute the mean score as well as the std (round the mean and std to 3 decimal d\n",
    "igits)\r\n",
    "Which C leads to the best mean ?\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92643dad-551c-44fd-8a10-a365b0315100",
   "metadata": {},
   "outputs": [],
   "source": [
    "?\n",
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
